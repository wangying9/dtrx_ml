{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ac0fb75-899d-4d1a-b9e4-c58f873e0772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99b776f3-fd27-4b89-ba2e-244a110e8f59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "prerequisites: \n",
    "1. Create a retail volume using UI in unity catalog. This reflects a volume directory for raw data: dbfs:/Volumes/dbacademy/labuser9128531_1738705451/retail/\n",
    "2. Create a folder in dbfs system to hold the rwa data\n",
    "3. Set current catalog, schema in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ecdaa3b-67e4-4eda-a27f-fde66d4c5ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set current catalog, schema and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71361579-fbe3-4d38-8159-76ea6e784319",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6671d74-f5c8-4307-ba01-61b9ccf32a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9f5ccd-b237-4a7c-9615-a3db97ca8068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5d9fba-8e6d-41da-8102-3f060f4347cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path='dbfs:/wy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f298b5f-26d0-44fe-bcf2-8a9355a94afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user=dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc6aaf50-30f0-4cc1-8c34-1d5476f25234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812daadd-9b38-4185-b5a3-192c5f26f690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "volumeName='air' # new creation \n",
    "catalog='dbacademy'\n",
    "catalogAndSchema='labuser9128531_1739377194'\n",
    "# useCase\n",
    "# userId='labuser9128531_1739377194_vocareum_com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a621d4b-8b62-4875-a7e7-0f64a2bbab15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workingDirectory='dbfs:/wy' # new creation\n",
    "workingVolumeDirectory='dbfs:/Volumes/dbacademy/labuser9128531_1739377194/retail/' #new creation\n",
    "rawDataVolume=workingVolumeDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6cba59b-c2cc-4b15-98d1-0720d82508de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# deltaTablesDirectory='dbfs:/wy/delta_tables'\n",
    "# dltPipelinesOutputDataDirectory='dbfs:/Volumes/dbacademy/labuser9128531_1738705451/dlt_pipelines' # new creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b56d89d-db5f-4a13-ba02-4b9e94fc6646",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# rawDataDirectory = \"/cloud_lakehouse_labs/retail/raw\" #???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb084032-1d89-469b-b02c-eccfb6c38777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create raw data in volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401464e6-8dfe-400b-abe8-cb3ad026e49c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from faker import Faker\n",
    "from collections import OrderedDict \n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def cleanup_folder(path):\n",
    "  for f in dbutils.fs.ls(path):\n",
    "    if f.name.startswith('_committed') or f.name.startswith('_started') or f.name.startswith('_SUCCESS') :\n",
    "      dbutils.fs.rm(f.path)\n",
    "\n",
    "def fake_date_between(months=0):\n",
    "  start = datetime.now() - timedelta(days=30*months)\n",
    "  return F.udf(lambda: fake.date_between_dates(date_start=start, date_end=start + timedelta(days=30)).strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "\n",
    "fake = Faker()\n",
    "#user defined function to generate fake data\n",
    "fake_firstname = F.udf(fake.first_name)\n",
    "fake_lastname = F.udf(fake.last_name)\n",
    "fake_email = F.udf(fake.ascii_company_email)\n",
    "#convert to a str series using soecified date_format\n",
    "fake_date = F.udf(lambda:fake.date_time_this_month().strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "fake_date_old = F.udf(lambda:fake.date_between_dates(date_start=datetime(2012,1,1), date_end=datetime(2015,12,31)).strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "fake_address = F.udf(fake.address)\n",
    "channel = OrderedDict([(\"WEBAPP\", 0.5),(\"MOBILE\", 0.1),(\"PHONE\", 0.3),(None, 0.01)])\n",
    "fake_channel = F.udf(lambda:fake.random_elements(elements=channel, length=1)[0])\n",
    "fake_id = F.udf(lambda: str(uuid.uuid4()) if random.uniform(0, 1) < 0.98 else None)\n",
    "countries = ['FR', 'USA', 'SPAIN']\n",
    "fake_country = F.udf(lambda: countries[random.randint(0,2)])\n",
    "\n",
    "def get_df(size, month):\n",
    "  df = spark.range(0, size).repartition(10)\n",
    "  df = df.withColumn(\"id\", fake_id())\n",
    "  df = df.withColumn(\"firstname\", fake_firstname())\n",
    "  df = df.withColumn(\"lastname\", fake_lastname())\n",
    "  df = df.withColumn(\"email\", fake_email())\n",
    "  df = df.withColumn(\"address\", fake_address())\n",
    "  df = df.withColumn(\"channel\", fake_channel())\n",
    "  df = df.withColumn(\"country\", fake_country())  \n",
    "  df = df.withColumn(\"creation_date\", fake_date_between(month)())\n",
    "  df = df.withColumn(\"last_activity_date\", fake_date())\n",
    "  df = df.withColumn(\"gender\", F.round(F.rand()+0.2))\n",
    "  return df.withColumn(\"age_group\", F.round(F.rand()*10))\n",
    "\n",
    "\n",
    "def generateRawData():\n",
    "  #size=133, month=12*30\n",
    "    df_customers = get_df(133, 12*30).withColumn(\"creation_date\", fake_date_old())\n",
    "    for i in range(1, 24):\n",
    "        df_customers = df_customers.union(get_df(2000+i*200, 24-i))\n",
    "\n",
    "    df_customers = df_customers.cache()\n",
    "\n",
    "    ids = df_customers.select(\"id\").collect()\n",
    "    ids = [r[\"id\"] for r in ids]\n",
    "\n",
    "    #Number of order per customer to generate a nicely distributed dataset\n",
    "    np.random.seed(0)\n",
    "    mu, sigma = 3, 2 # mean and standard deviation\n",
    "    s = np.random.normal(mu, sigma, int(len(ids)))\n",
    "    s = [i if i > 0 else 0 for i in s]\n",
    "\n",
    "    #Most of our customers have ~3 orders\n",
    "    count, bins, ignored = plt.hist(s, 30, density=False)\n",
    "    plt.show()\n",
    "    s = [int(i) for i in s]\n",
    "\n",
    "    order_user_ids = list()\n",
    "    action_user_ids = list()\n",
    "    for i, id in enumerate(ids):\n",
    "        for j in range(1, s[i]):\n",
    "            order_user_ids.append(id)\n",
    "            #Let's make 5 more actions per order (5 click on the website to buy something)\n",
    "            for j in range(1, 5):\n",
    "                action_user_ids.append(id)\n",
    "        \n",
    "    print(f\"Generated {len(order_user_ids)} orders and  {len(action_user_ids)} actions for {len(ids)} users\")\n",
    "\n",
    "    # ORDERS DATA\n",
    "    orders = spark.createDataFrame([(i,) for i in order_user_ids], ['user_id'])\n",
    "    orders = orders.withColumn(\"id\", fake_id())\n",
    "    orders = orders.withColumn(\"transaction_date\", fake_date())\n",
    "    orders = orders.withColumn(\"item_count\", F.round(F.rand()*2)+1)\n",
    "    orders = orders.withColumn(\"amount\", F.col(\"item_count\")*F.round(F.rand()*30+10))\n",
    "    orders = orders.cache()\n",
    "    orders.repartition(10).write.format(\"json\").mode(\"overwrite\").save(rawDataVolume+\"/orders\")\n",
    "    cleanup_folder(rawDataVolume+\"/orders\")\n",
    "\n",
    "    # WEBSITE ACTIONS DATA\n",
    "    platform = OrderedDict([(\"ios\", 0.5),(\"android\", 0.1),(\"other\", 0.3),(None, 0.01)])\n",
    "    fake_platform = F.udf(lambda:fake.random_elements(elements=platform, length=1)[0])\n",
    "\n",
    "    action_type = OrderedDict([(\"view\", 0.5),(\"log\", 0.1),(\"click\", 0.3),(None, 0.01)])\n",
    "    fake_action = F.udf(lambda:fake.random_elements(elements=action_type, length=1)[0])\n",
    "    fake_uri = F.udf(lambda:re.sub(r'https?:\\/\\/.*?\\/', \"https://databricks.com/\", fake.uri()))\n",
    "\n",
    "    actions = spark.createDataFrame([(i,) for i in order_user_ids], ['user_id']).repartition(20)\n",
    "    actions = actions.withColumn(\"event_id\", fake_id())\n",
    "    actions = actions.withColumn(\"platform\", fake_platform())\n",
    "    actions = actions.withColumn(\"date\", fake_date())\n",
    "    actions = actions.withColumn(\"action\", fake_action())\n",
    "    actions = actions.withColumn(\"session_id\", fake_id())\n",
    "    actions = actions.withColumn(\"url\", fake_uri())\n",
    "    actions = actions.cache()\n",
    "    actions.write.format(\"csv\").option(\"header\", True).mode(\"overwrite\").save(rawDataVolume+\"/events\")\n",
    "    cleanup_folder(rawDataVolume+\"/events\")\n",
    "\n",
    "    # CHURN COMPUTATION AND USER GENERATION\n",
    "\n",
    "    #Let's generate the Churn information. We'll fake it based on the existing data & let our ML model learn it\n",
    "    churn_proba_action = actions.groupBy('user_id').agg({'platform': 'first', '*': 'count'}).withColumnRenamed(\"count(1)\", \"action_count\")\n",
    "    #Let's count how many order we have per customer.\n",
    "    churn_proba = orders.groupBy('user_id').agg({'item_count': 'sum', '*': 'count'})\n",
    "    churn_proba = churn_proba.join(churn_proba_action, ['user_id'])\n",
    "    churn_proba = churn_proba.join(df_customers, churn_proba.user_id == df_customers.id)\n",
    "\n",
    "    #Customer having > 5 orders are likely to churn\n",
    "\n",
    "    churn_proba = (churn_proba.withColumn(\"churn_proba\", 5 +  F.when(((col(\"count(1)\") >=5) & (col(\"first(platform)\") == \"ios\")) |\n",
    "                                                                    ((col(\"count(1)\") ==3) & (col(\"gender\") == 0)) |\n",
    "                                                                    ((col(\"count(1)\") ==2) & (col(\"gender\") == 1) & (col(\"age_group\") <= 3)) |\n",
    "                                                                    ((col(\"sum(item_count)\") <=1) & (col(\"first(platform)\") == \"android\")) |\n",
    "                                                                    ((col(\"sum(item_count)\") >=10) & (col(\"first(platform)\") == \"ios\")) |\n",
    "                                                                    (col(\"action_count\") >=4) |\n",
    "                                                                    (col(\"country\") == \"USA\") |\n",
    "                                                                    ((F.datediff(F.current_timestamp(), col(\"creation_date\")) >= 90)) |\n",
    "                                                                    ((col(\"age_group\") >= 7) & (col(\"gender\") == 0)) |\n",
    "                                                                    ((col(\"age_group\") <= 2) & (col(\"gender\") == 1)), 80).otherwise(20)))\n",
    "\n",
    "    churn_proba = churn_proba.withColumn(\"churn\", F.rand()*100 < col(\"churn_proba\"))\n",
    "    churn_proba = churn_proba.drop(\"user_id\", \"churn_proba\", \"sum(item_count)\", \"count(1)\", \"first(platform)\", \"action_count\")\n",
    "    churn_proba.repartition(100).write.format(\"json\").mode(\"overwrite\").save(rawDataVolume+\"/users\")\n",
    "    cleanup_folder(rawDataVolume+\"/users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9da62746-7bbf-408d-8073-32fab21a9380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def existsAndNotEmptyDirectory(directoryPath):\n",
    "    try:\n",
    "        output = dbutils.fs.ls(directoryPath)\n",
    "        return len(output) > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if (not existsAndNotEmptyDirectory(rawDataVolume)) or \\\n",
    "    (not existsAndNotEmptyDirectory(rawDataVolume + \"/users\")) or \\\n",
    "    (not existsAndNotEmptyDirectory(rawDataVolume + \"/events\")) or \\\n",
    "    (not existsAndNotEmptyDirectory(rawDataVolume + \"/orders\")):\n",
    "    print(\"Generating the raw data\")\n",
    "    generateRawData()\n",
    "else:\n",
    "    print(\"Raw data already exists\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4678823810710975,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "0-createdata",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
