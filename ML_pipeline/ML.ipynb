{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ecc8088-a6d7-4e8a-9b2b-8193926f93b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80a6090a-4d1c-41f0-a9a1-71cb034123fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read data from gold layer to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e275f1da-79c9-4013-8ae9-c9967e2cc4d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read our churn_features table\n",
    "churn_dataset = spark.table(\"churn_features\")\n",
    "display(churn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0690f7ee-0ce1-4a54-9a8d-c10864b6793e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Convert it to pandas on spark and Remove a few unrelevant cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55dbd219-9092-41c6-a959-1a479d9a00af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to pandas on spark\n",
    "dataset = churn_dataset.pandas_api()\n",
    "dataset.describe()  \n",
    "# Drop columns we don't want to use in our model\n",
    "dataset = dataset.drop(columns=['address', 'email', 'firstname', 'lastname', 'creation_date', 'last_activity_date', 'last_event'])\n",
    "# Drop missing values\n",
    "dataset = dataset.dropna()\n",
    "# print the ten first rows\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2174515f-2181-4779-aa91-5d2061d50b10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d248933b-1021-4919-8544-052aef55026f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write to feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e314be1-200d-4b22-84e6-c43c1d67e0fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "In 'Features', there should be a feature table. And a physical table 'churn_user_features' is added to catalog.schema   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a8f239-d84b-4e2b-be78-00b4399d1b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "try:\n",
    "  #drop table if exists\n",
    "  fs.drop_table('churn_user_features')\n",
    "except: pass\n",
    "\n",
    "#Note: You might need to delete the FS table using the UI\n",
    "churn_feature_table = fs.create_table(\n",
    "  name='churn_user_features',\n",
    "  primary_keys='user_id',\n",
    "  schema=dataset.spark.schema(),\n",
    "  description='These features are derived from the churn_bronze_customers table in the lakehouse.  We created dummy variables for the categorical columns, cleaned up their names, and added a boolean flag for whether the customer churned or not.  No aggregations were performed.'\n",
    ")\n",
    "\n",
    "fs.write_table(df=dataset.to_spark(), name='churn_user_features', mode='overwrite')\n",
    "features = fs.read_table('churn_user_features')\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c111cf3-f873-4830-bc16-1272bd1699bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Training a model from the table in the Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5b587a2-9f61-4e15-824b-e4af9a46fa35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert feature table to a pandas model since we use scikit learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8cd1a42-98c3-4c0a-9fd7-e9ee15b19ee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas\n",
    "df = features.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf7cb74-1d3d-4c8d-804e-9a29947eecbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split to train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e38ac27-4f6c-4487-8e7b-4f1a63600cdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the columns\n",
    "from databricks.automl_runtime.sklearn.column_selector import ColumnSelector\n",
    "supported_cols = [\"event_count\", \"gender\", \"total_amount\", \"country\", \"order_count\", \"channel\", \"total_item\", \"days_since_last_activity\", \"days_last_event\", \"days_since_creation\", \"session_count\", \"age_group\", \"platform\"]\n",
    "col_selector = ColumnSelector(supported_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a745b5-ebcd-42b9-9f64-f6f140c21511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "num_imputers = []\n",
    "num_imputers.append((\"impute_mean\", SimpleImputer(), [\"age_group\", \"days_last_event\", \"days_since_creation\", \"days_since_last_activity\", \"event_count\", \"gender\", \"order_count\", \"session_count\", \"total_amount\", \"total_item\"]))\n",
    "\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    (\"converter\", FunctionTransformer(lambda df: df.apply(pd.to_numeric, errors=\"coerce\"))),\n",
    "    (\"imputers\", ColumnTransformer(num_imputers)),\n",
    "    (\"standardizer\", StandardScaler()),\n",
    "])\n",
    "\n",
    "numerical_transformers = [(\"numerical\", numerical_pipeline, [\"event_count\", \"gender\", \"total_amount\", \"order_count\", \"total_item\", \"days_since_last_activity\", \"days_last_event\", \"days_since_creation\", \"session_count\", \"age_group\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45227b2a-e92b-4ae6-9332-e934a7cbb6fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Treating categorical variables\n",
    "from databricks.automl_runtime.sklearn import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "one_hot_imputers = []\n",
    "one_hot_pipeline = Pipeline(steps=[\n",
    "    (\"imputers\", ColumnTransformer(one_hot_imputers, remainder=\"passthrough\")),\n",
    "    (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"indicator\")),\n",
    "])\n",
    "categorical_one_hot_transformers = [(\"onehot\", one_hot_pipeline, [\"age_group\", \"channel\", \"country\", \"event_count\", \"gender\", \"order_count\", \"platform\", \"session_count\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ee5d721-a3be-43a4-91bc-0c2ad9f48b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Final transformation of the columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "transformers = numerical_transformers + categorical_one_hot_transformers\n",
    "preprocessor = ColumnTransformer(transformers, remainder=\"passthrough\", sparse_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f57087f-6bca-4baf-9368-3c41816f6daf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Separate target column from features\n",
    "target_col = \"churn\"\n",
    "X_train = train_df.drop([target_col], axis=1)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop([target_col], axis=1)\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b0bb22-bad3-4bb9-9a7f-ffcf2853a658",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "start mlflow"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.models import Model\n",
    "from mlflow import pyfunc\n",
    "from mlflow.pyfunc import PyFuncModel\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Start a run\n",
    "with mlflow.start_run(run_name=\"simple-RF-run\") as run:\n",
    "  classifier = RandomForestClassifier()\n",
    "  model = Pipeline([\n",
    "      (\"column_selector\", col_selector),\n",
    "      (\"preprocessor\", preprocessor),\n",
    "      (\"classifier\", classifier),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2251a6c4-f871-46a3-9451-b73127aa0fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Split the codes to three cells. There are three files in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7794af7c-4c67-4e72-8f5f-40caa000d87a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "auto log"
    }
   },
   "outputs": [],
   "source": [
    "  # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "  mlflow.sklearn.autolog(\n",
    "      log_input_examples=True,\n",
    "      silent=True)\n",
    "  model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0751f18b-4583-4859-9cc1-f760afb9fefe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Log test"
    }
   },
   "outputs": [],
   "source": [
    "  # Log metrics for the test set\n",
    "  mlflow_model = Model()\n",
    "  pyfunc.add_to_model(mlflow_model, loader_module=\"mlflow.sklearn\")\n",
    "  pyfunc_model = PyFuncModel(model_meta=mlflow_model, model_impl=model)\n",
    "  X_test[target_col] = y_test\n",
    "  test_eval_result = mlflow.evaluate(\n",
    "      model=pyfunc_model,\n",
    "      data=X_test,\n",
    "      targets=target_col,\n",
    "      model_type=\"classifier\",\n",
    "      evaluator_config = {\"log_model_explainability\": False,\n",
    "                          \"metric_prefix\": \"test_\" , \"pos_label\": 1 }\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fab19b1f-2030-417f-a755-d13de8abcb6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "One cell will put all the results into a file in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00118a76-2e83-4d8f-9e90-f4d4fb282509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"simple-RF-run2\") as run:\n",
    "  classifier = RandomForestClassifier()\n",
    "  model = Pipeline([\n",
    "      (\"column_selector\", col_selector),\n",
    "      (\"preprocessor\", preprocessor),\n",
    "      (\"classifier\", classifier),\n",
    "  ])\n",
    "\n",
    "  # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "  mlflow.sklearn.autolog(\n",
    "      log_input_examples=True,\n",
    "      silent=True)\n",
    "\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Log metrics for the test set\n",
    "  mlflow_model = Model()\n",
    "  pyfunc.add_to_model(mlflow_model, loader_module=\"mlflow.sklearn\")\n",
    "  pyfunc_model = PyFuncModel(model_meta=mlflow_model, model_impl=model)\n",
    "  X_test[target_col] = y_test\n",
    "  test_eval_result = mlflow.evaluate(\n",
    "      model=pyfunc_model,\n",
    "      data=X_test,\n",
    "      targets=target_col,\n",
    "      model_type=\"classifier\",\n",
    "      evaluator_config = {\"log_model_explainability\": False,\n",
    "                          \"metric_prefix\": \"test_\" , \"pos_label\": 1 }\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f8e41f8-96d4-4c22-9a3d-349ebea23584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77bac2b1-323d-44ee-99ac-096f0c1b9de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "register mode to 'Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab12733-1525-404b-bbbb-956947d4fadf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a96a718d-1ccf-490f-859c-8428b1cc3894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "modelName='RF2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be8cc7fe-f4aa-4d4a-9da3-2bfaee330bc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This saved model to catalog.schema and also show the model in 'Models', indicating the model is registered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3448e4-98e7-4d2f-aba3-fae3f41b8573",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register the model in the model registry"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "logged_model = 'runs:/' + run.info.run_id + '/model'\n",
    "\n",
    "print(\"Registeting the model under the name '\" + modelName + \"'\")\n",
    "result=mlflow.register_model(logged_model, 'dbacademy.labuser9128531_1738705451.'+modelName, await_registration_for=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89b6da90-a8e4-49bc-92ba-6be3d547d1c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Retrieving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29069d9b-69f4-40c7-849f-20f2649d5e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f315b404-856b-4b58-987b-b75cc0fb2d29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6481ef3b-ac95-4678-a0b8-aaee593f3108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "client.get_model_version(name='dbacademy.labuser9128531_1738705451.'+modelName, version=result.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf66ba5b-8631-4067-bcec-2f86b0cb8bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When performing an automated model training and registration process, this code can be used to ensure that the model is fully available and ready before performing any further operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62ae886-ef57-42e4-b1d3-ca5795a271ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrieving the model\n",
    "import time\n",
    "client = MlflowClient() # query about model version, info\n",
    "model_version_details = None\n",
    "while True:\n",
    "  model_version_details = client.get_model_version(name='dbacademy.labuser9128531_1738705451.'+modelName, version=result.version)\n",
    "  if model_version_details.status == 'READY': break\n",
    "  time.sleep(5) #If the model's status is not 'READY', the code will wait for 5 seconds before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08014923-6ff9-4a75-8f2a-2a5b0320b32a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(model_version_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80b18a81-452d-4a9c-b0ce-0e13c30a9c74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set up model as produciton \n",
    "client.transition_model_version_stage has been  deprecated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db805703-5799-4e77-970d-820c1606f1c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create \"production\" alias for version 1 of model \"RF2\"\n",
    "client.set_registered_model_alias('dbacademy.labuser9128531_1738705451.'+modelName, \"production\", 1)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7718552896074657,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
